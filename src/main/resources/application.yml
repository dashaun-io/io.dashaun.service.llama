spring:
    ai:
        ollama:
            base-url: http://ollama.dashaun-io.svc.cluster.local:11434
            chat:
                options:
                    model: llama2
    threads:
        virtual:
            enabled: true
